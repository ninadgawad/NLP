# BERT - [Bidirectional Encoder Representations from Transformers](https://arxiv.org/pdf/1810.04805v2.pdf)
* It is a multi layer bidirectional transformer 
* It make use of positinal embeddings 
* Ecoder based 

# It can be use to perform multiple taks like:
* NER or Entities recognition
* Paraphrase 
* Generate Summary
