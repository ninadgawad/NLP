# BERT - [Bidirectional Encoder Representations from Transformers](https://arxiv.org/pdf/1810.04805v2.pdf)
* It is a multi layer bidirectional transformer 
* It make use of positinal embeddings 
* Ecoder based 

# It can be use to perform multiple taks like:
* NER or Entities recognition
* Paraphrase 
* Generate Summary


# T5 - [Text-To-Text Transfer Transformer](https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html)
* It uses transfer learning 
* Can be used for Classification, Q&A, Machine Translation, Summarization or Sentiment analysis and much more
* It uses Encoder/Decoder (Masked Language Modeling)


# GLUE [General Language Understanding Evaluation]
* Its used to traind , evalute and analyze NLP systems
* Task evaluated on Sentence is grammatically corect or not , Sentiment, Paraphrase, Contradiction, Similarity etc.. 
* Used to drive research 
* Its model agnostic 
* Makesd use of transfer learning 

